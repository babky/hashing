\section{Obtaining the limit function}
\label{section-limit}
Limit functions play a crucial role in our model. The lower the values of a limit function the better warranty is obtained. Apparently each limit function depends on the size of the table and the load factor. However, our concept also estimates the probability that a selected function creates a chain longer than the predefined limit. When thinking about this probability, there are two choices standing against each other. The lower the limit the greater the probability of a random function being unsuitable.

\begin{definition}[Limit function, trimming rate, suitable function]
Let $l\colon \bbbn \times \mathbb{R}_0^+ \times (0, 1) \rightarrow \bbbn$ and $p \in (0, 1)$.  We say that $l$ is a \emph{limit function} with \emph{trimming rate} $p$ if $\Prob{\lpsl > l(m, \alpha, p)} \leq p$.

Let $l$ be a limit function with a trimming rate $p$. We say that a function $f \in H$ \emph{does not create a long chain}, or equivalently is \emph{suitable}, if $\lpsl < l(m, \alpha, p)$ where $\lpsl$ is the value of the random variable $\lpsl$ for the the function $f$.
\end{definition}

Notice one way of extraction of a limit function when we known $\Expect{\lpsl}$. From Markov inequality it follows that $\Prob{\lpsl > k \Expect{\lpsl}} \leq \frac{1}{k}$. Better limit functions may be found if we have an upper bound on probability distribution function of the random variable $\lpsl$.

\subsection{Linear hash functions}
Alon, Dietzfelbinger, Bro Miltersen, Petrank and Tardos \cite{DBLP:journals/jacm/AlonDMPT99} found an interesting upper bound on $\Expect \lpsl$. They used the system of all linear functions between two vector spaces over the field $\bbbz_2$. Representing $U$ and $V$ as vector spaces does not cause any problem. Each key -- binary number may be represented as a vector from a sufficiently large vector space over $\bbbz_2$. If the initial size of the hash table is a power of two and Rehash may only double or halve it, then $V$ is always a vector space over $\bbbz_2$.

\begin{theorem}[\cite{DBLP:journals/jacm/AlonDMPT99}]
\label{theorem-linear-hash-functions-dietzefelbinger}
Suppose universal hashing with the system of linear functions from $U$ to $V$. When storing $m \log m$ elements $\Expect{\lpsl} = \bigo(\log m \log \log m)$. 
\end{theorem}

The major problem of Theorem \ref{theorem-linear-hash-functions-dietzefelbinger} is the high multiplicative constant. It can be significantly reduced by a refinement of the original proof. First, in order to obtain a valid limit function a dependence of $\lpsl$ on $\alpha$ needs to be discovered. Further improvement is obtained by storing $n$ elements for $n = \bige(m)$ instead of $n = m \log m$. In our computations we also introduced some variables and optimized their values in order to reduce the multiplicative constant.

\begin{theorem}
Assume universal hashing with the system of all linear transformations between vector spaces over $\bbbz_2$. When storing $n = \bige(m)$ elements, then $$\Expect{\lpsl} \leq 538 \alpha \log n \log \log n + 44,$$ $$\Prob{\lpsl \geq 57.29 \log m \log \log m} < 0.5.$$
\end{theorem}

Let us note that the exact constants for different probabilities and load factors can be found by a simple computer program. Now we need only the stated results.

\subsection{Two choices paradigm}
The two choices paradigm comes from the area of balls and bins systems. For separate chaining with a single perfectly random function it is known that $\Expect{\lpsl} = \bigo\left({\log n}/{\log \log n}\right)$. A proof of this bound may be found in \cite{DBLP:books/sp/Mehlhorn84}. Similarly with a single function chosen from an almost uniform system the same bound holds. On the other hand with a limited independence this problem becomes harder and general bounds for universal hashing are not available.

A further study of balls and bins systems discovered that hashing with $d$, $d \geq 2$, independent fully random hash functions brings far better results \cite{DBLP:conf/stoc/AzarBKU94}. If each stored element is put inside a least loaded bin of $d$ ones, we obtain longest chains which do not contain more than ${\ln \ln n}/{\ln d} + \bigo(1)$ elements with high probability. It is not so hard to realize that these results hold in case of universal hashing with almost uniform systems. Bounds, that are possible to achieve with a limited independence for a general $S \subset U$, are not known so far.

In the following definition for a $\vec{x} \in U^k$ and $f \in H$ the notation $f(\vec{x})$ means a vector from $V^k$ and $f(\vec{x}) = (f(x_1), \dots, f(x_k))$.
\begin{definition}[Independent hash functions]
\label{definition-independent-hash-functions}
Let $H$ be a uniform system of hash functions and $f, g \in H$ be two functions chosen uniformly at random from the system $H$. We say that the functions $f, g$ are \emph{independent} if for each $\vec{x} \in U^n$ with different elements and arbitrary $y, z \in V^n$ $$\Prob{f(\vec{x}) = \vec{y}, g(\vec{x}) = \vec{z}} = \Prob{f(\vec{x}) = \vec{y}} \Prob{g(\vec{x}) = \vec{z}}.$$
\end{definition}

Notice that the independent choice of $f_1, \dots, f_d$ from $H$ is sufficient for the functions to be independent in terms of Definition \ref{definition-independent-hash-functions}. Theorem \ref{theorem-universal-hashing-two-choices} is a straightforward restatement of results pioneered in \cite{DBLP:conf/stoc/AzarBKU94} which originally hold only with fully random functions.

\begin{theorem}
\label{theorem-universal-hashing-two-choices}
Let $H$ be an almost uniform universal system with constant $c > 0$, $n \leq m$ and $c \alpha \leq 1$. Assume that $d$ independent hash functions $f_1, \dots, f_d$ are chosen uniformly from $H$ and each stored element $x \in S$ is placed inside the shortest chain of chains $f_1(x), \dots, f_d(x)$. Then for each $S \in U$ $$\Prob{\lpsl > \frac{\ln \ln n}{\ln d} + 7} \in \littleo\left(\frac{1}{n}\right).$$
\end{theorem}
\begin{proof}
We only point out problems that appear in the proof for perfectly random functions given in \cite{Mitzenmacher:2005:PCR:1076315}. Observe that the probability of collision of $k$, $k \leq n$, different elements is at most $c$ times higher than ${1}/{m^k}$ -- the probability of collision of the same sequence of elements with a truly random function. From independence of the $d$ chosen function it is clear that $\Prob{f(x) \in R, g(x) \in R} = \Prob{f(x) \in R}\Prob{g(x)\in R}$ for arbitrary $x \in U$ and $R \subseteq V$. So if $c = 1$, then no change has to be done. In the case when $c > 1$, however our assumption $\alpha c \leq 1$ is sufficient for the result to hold.
\qed
\end{proof}

The last thing that has to be discussed what is the efficiency of a uniform system. It is obvious that system of all functions is $\omega$-universal and thus uniform but. The main problem is encoding of such system which requires $\bigo(|U| \log |V|)$ bits. Other $\omega$-universal classes are known but they are quite large. Despite the fact that hash values may be computed within a constant time these classes are complex and not efficient enough. 

A more suitable example of a uniform system appeared in \cite{DBLP:journals/siamcomp/PaghP08}. It is uniform with a high probability as stated in Theorem \ref{theorem-uniform-system}.
\begin{theorem}[\cite{DBLP:journals/siamcomp/PaghP08}]
\label{theorem-uniform-system}
For any constant $c > 0$ there is a RAM algorithm constructing a random family of functions from $U$ to $V$ in expected $\littleo(n) + (\log \log|U|)^{\bigo(1)}$ time and $\littleo(n)$ words of space, such that:
\begin{itemize}
\item With probability $1 - \bigo(1 / n^c)$ the family is uniform on $S$.
\item There is a RAM data structure of $\bigo(n \log|V| + \log \log|U|)$ bits, which is optimal, representing its functions such that function values can be computed in constant time. The data structure can be initialized to a random function in $\bigo(n)$ time.
\end{itemize}
\end{theorem}

Let us note that for this system we use RAM having words of size $\bige(\log |U| + \log |V|)$. Now since the construction of the system is probabilistic there is only a certain probability that the system is good. So the probability that our estimate for the limit function holds may be computed as 
\[
\begin{split} 
& \Prob{\lpsl \leq \frac{\ln \ln n}{\ln d} + 7 \mbox{ and } H \mbox{ is uniform}} \\
	& \qquad = \Prob{\lpsl \leq \frac{\ln \ln n}{\ln d} + 7 | H \mbox{ is uniform}} \Prob{H \mbox{ is uniform}} \\ 
	& \qquad = \left(1 - \littleo\left(\frac{1}{n}\right)\right)\left(1 - \bigo\left(\frac{1}{n^c}\right)\right). \\
\end{split}
\]
The positive fact is that this probability tends to one as $n$ increases. The negative fact is that with this system choosing a new function means regenerating the whole system.

\subsection{Truly random functions}
\label{subsection-truly-random-functions}
In \cite{DBLP:conf/soda/MitzenmacherV08} there are many examples when strong $2$-universality is sufficient for the results obtained with truly random functions to hold. Good performance arises from combination of randomness and data. Simply said if new data (stored elements) has some entropy given old data (already stored elements), then the performance of $2$-wise functions has high quality. With these assumptions we can use limit functions holding for truly random functions.

In case of two choices paradigm the limit function is $\bigo(\log \log n / \log d)$ and with a single hash function $\bigo(\log n / \log \log n)$. However bounds discussed above hold for arbitrary stored set without any other assumption and rely on the randomness inherited in the used universal system what may be inefficient in some situations.



