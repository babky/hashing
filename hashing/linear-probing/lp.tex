\documentclass[12pt,notitlepage]{report}
\pagestyle{plain}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{remark}[definition]{Remark}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{example}[definition]{Example}
\newtheorem{claim}[definition]{Claim}
\newtheorem{statement}[definition]{Statement}
\renewcommand{\theequation}{\arabic{chapter}.\arabic{definition}}

\newcommand{\setdelim}{\mid}
\newcommand{\Prob}[1]{\mathbf{Pr}\left(#1\right)}
\newcommand{\Expect}[1]{\mathbf{E}\left(#1\right)}
\newcommand{\Variance}[1]{\mathbf{Var}\left(#1\right)}
\newcommand{\maxlength}{\mathbf{max\mbox{-}length}}
\newcommand{\length}{\mathbf{length}}
\newcommand{\Indicator}{\mathbf{I}}
\newcommand{\rank}[1]{\mathrm{rank}\left({#1}\right)}
\newcommand{\dimension}[1]{\mathrm{dim}\left({#1}\right)}
\newcommand{\nullspace}[1]{\mathcal{N}\left({#1}\right)}
\newcommand{\matrixkernel}[1]{\mathrm{Ker}\left({#1}\right)}
\newcommand{\vecspan}[1]{\mathrm{span}\left({#1}\right)}
\newcommand{\vecspace}[1]{\mathbb{Z}_{2}^{#1}}

\title{Expected Length of the Probe Sequence for Linear Probing}

\begin{document}

\maketitle

We are trying to estimate the expected length of the probe sequence in the unsuccessful case.
We are going to estimate the expectation in the two following models.

The first model is called Simple Hashing, the other one we call Universal Hashing.

\section{Model of Simple Hashing}

First, we assume that there is a single hash function $h$. In this model we only have a probability space with the following properties.

\begin{itemize}
\item The hash function distributes uniformly.
\[
	\Prob{h(x) = y} = \frac{1}{m} \mbox{ where } x \in U, y \in [m].
\] 

\item The hash values for $k$ different elements are independent. Choose $k$ different elements $x_1, \dots, x_k \in  U$ and their hash values $y_1, \dots, y_k \in [m]$, the events $h(x_i) = y_i, i \in [k]_0$ are mutually independent.
\end{itemize}

The expected length can be computed as follows. Fix an element $x \in U$ such that $x \not \in S$. We are estimating
\[
\begin{split}
& \Expect{\mbox{length of the probe sequence}} = \\
	& \qquad = \sum_{k = 0}^{n - 1} \Prob{x\mbox{ would be placed at the position }h(x) + k}.
\end{split}
\]

Also observe that the number of tests required to say that $x \not \in S$ equals to the length of the probe sequence plus one.

Let $p(x)$ denote the position of $x$ in the table. We can observe that $p(x) \geq h(x) + k \equiv \exists s \in \{0, \dots, n - k\}$ and there are $k + s$  elements stored at the positions $\{h(x) - s + 1, \dots, h(x) + k\}.$

Now let us denote the $k + s$ elements as $x_1, \dots, x_{k + s}$. Without loss of generality we may assume that they are sorted in the ascending order of their hash value. If we cycle over the table, then we consider the smallest value of the hash value to be $h(x) - s + 1$. 

Observe that $h(x_1) = h(x) - s + 1$ and that $h(x_i) \in \{h(x_1), \dots, h(x_1) + i\}$. For each $i$ it holds that $\Prob{h(x_i) \in \{h(x_1), \dots, h(x_1) + i\}} \leq \frac{i}{m}$.

There are ${n \choose k + s}$ choices of the $k + s$ elements.

Thus
\[
\begin{split}
& \Prob{p(x) \geq h(x) + k} \\ 
& \qquad \leq \sum_{s = 0}^{n - k} {n \choose k + s} \cdot \frac{(s + k)!}{m^{s+k}} \\
& \qquad \leq \sum_{s=0}^\infty \alpha^{k + s} \\
& \qquad \leq \sum_{s=0}^\infty \alpha^{k} \alpha^{s} \\
& \qquad = \frac{\alpha ^ k}{1 - \alpha}.
\end{split}
\]

We may now estimate the length of the probe sequence as
\[
\sum_{k = 0}^{n - 1} \frac{\alpha^k}{1-\alpha} \leq \frac{1}{(1 - \alpha)^2}.
\]

The expected number of tests in the unsuccessful case is thus at most $1 + \frac{1}{(1 - \alpha)^2}$.

\section{The successful case}

We compute the number of tests in the successful case using the standard trick as follows.

\[
\begin{split}
\frac{1}{n} \int_{1}^{n + 1} \left(1 + \frac{1}{(1 - i/m) ^ 2}\right) di & = 1 + \frac{\int_{1/m}^{(n + 1)/m} \frac{m}{(1 - \alpha)^2} d\alpha}{n} = 1 + \frac{[\frac{m}{1-\alpha}]_{1/m}^{(n+1)/m}}{n} \\
& = 1 + \frac{\frac{m}{1 - (n + 1) / m} - \frac{m}{1 - 1/m}}{n} = 1 + \frac{\frac{m^2}{m - n - 1} - \frac{m^2}{m - 1}}{n} \\
& = 1 + \frac{\frac{m^2(m - 1) - m^2(m - n - 1)}{(m - n - 1)(m - 1)}}{n} = 1 + \frac{\frac{nm^2}{(m - n - 1)(m - 1)}}{n} \\
& = 1 + \frac{\frac{m^2(m - 1) - m^2(m - n - 1)}{(m - n - 1)(m - 1)}}{n} = 1 + \frac{\frac{nm^2}{(m - n - 1)(m - 1)}}{n} \\
& = 1 + \frac{m^2}{(m - n - 1)(m - 1)} = 1 + \frac{1}{\frac{m - n + 1}{m}\frac{m-1}{m}}\\
& \approx 1 + \frac{1}{1 - \alpha}
\end{split}
\]

\section{The Uniform Hashing}

The model is the universal hashing with $n$-wise independent hash function system. The main difference between the models is that the hash function is not fixed and thus we can not assume a fixed ordering of the set of the elements.

In the model of Simple Hashing we could assume that $\forall \omega \in \Omega \colon h(x)$ is a constant (for a fixed element $x$). In this system this condition does not hold any longer.

We do a different analysis in this case.

By the next lemma we establish an upper on the probability of the event that there is a probe sequence of length at least $l$ after an empty place.
\begin{lemma}
Let $y \in [m], l > 0$. Let $E_l$ be the event that there is a chain of length at least $l$ starting at the position $y$.
If the position $y - 1$ does not contain an element, then $\Prob{E_l} \leq e^{-l(1-\alpha)^2/(2 \alpha)}$.
\end{lemma}
\begin{proof}
Let $S$ be the hash set and assume that $S = \{x_1, \dots, x_n\}$.
Let $X_i$ be a binary indicator having the value $1$ iff $h(x_i) \in \{y, \dots, y + l - 1\}$.
Observe that $\Prob{X_i = 1} = l / m$.
Let $X = \sum_{i = 1}^n X_i$.
It immediately follows that $\Expect{X} = \alpha n$\footnote{We need $l$ elements to have such a chain, but we expect only $\alpha l$ elements to be hashed in the area.}.

Now from Chernoff bound\footnote{The uniformity assumption is used here.} it follows that 
\[
	\Prob{E} = \Prob{X > l} \leq \exp\left(\frac{-l^2(1 - \alpha)^2}{2\alpha l (1 - l/m)}\right) \leq \exp\left(\frac{-l(1 - \alpha)^2}{2\alpha}\right).
\]

For the following computations let $\beta = \exp\left(-\frac{(1 - \alpha)^2}{2\alpha}\right)$. Now we estimate the length of the probe sequence starting from any position.

\begin{lemma}
Let $y \in [m], k > 0$. Let $F_k$ be the event that there is a chain of length at least $k$ starting at the position $y$.
Then $\Prob{F_k} \leq \frac{\beta^k}{1 - \beta}$.
\end{lemma}
Observe that $F_k$ occurs iff $\exists s \in \{0, \dots n - k\}$ such that $E_{k + s}$ holds at the position $y - s$.
We can observe that
\[
\Prob{F_k} \leq \sum_{s = 0}^{n - k} \Prob{E_{k + s}} \leq \sum_{s = 0}^{\infty} e^{\frac{-(k + s)(1 - \alpha)^2}{2\alpha}} = \frac{\beta^k}{1 - \beta}.
\]
\end{proof}

Now we can simply estimate the length of the probe sequence as 
\[
\sum_{k = 0}^\infty \Prob{F_k} \leq \frac{1}{(1 - \beta)^2}.
\]

Finally observe that there are constants $c, d > 0$ such that $c(1 - \alpha) \leq 1 - \beta \leq d(1 - \alpha)$ when $\alpha \in [0, 1]$. Therefore the analysis in this case gives more or less the same result as in the previous analysis.
\end{document}
