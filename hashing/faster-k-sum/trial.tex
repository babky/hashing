\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{geometry}
\geometry{
	b5paper,
	margin=0.5cm,
	top=1.5cm,
	bottom=1.5cm
}

\newcommand{\llinnm}[2]{\operatorname{L}_{\operatorname{lin}}({#1}, {#2})}
\newcommand{\llinn}[1]{\llinnm{#1}{#1}}
\newcommand{\hlinr}[1]{\operatorname{H}_{\operatorname{lin}}^{#1}}
\newcommand{\hlin}{\operatorname{H}_{\operatorname{lin}}}
\newcommand{\hfact}[2]{\operatorname{H}_{\operatorname{factor}}({#1}, {#2})}
\newcommand{\rot}[2]{\operatorname{H}_{\operatorname{rot}}^{{#1}, {#2}}}

\newcommand{\bin}[3]{\operatorname{\mathbf{bin}}({#1}, {#2}, {#3})}
\newcommand{\lbin}[2]{\operatorname{\mathbf{lbin}}({#1}, {#2})}
\newcommand{\vbin}[2]{\operatorname{\mathbf{bin}}({#1}, {#2})}
\newcommand{\vlbin}[1]{\operatorname{\mathbf{lbin}}({#1})}


\newcommand{\probs}[2]{\operatorname{\mathbf{Pr}}_{{#1}}\left[{#2}\right]}
\newcommand{\prob}[1]{\probs{}{#1}}
\newcommand{\expects}[2]{\operatorname{\mathbf{E}}_{{#1}}\left[{#2}\right]}
\newcommand{\expect}[1]{\expects{}{#1}}
\newcommand{\inu}{\in_U}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}

\title{Faster $k$-SUM algorithm improvement on randomness requirements}
\author{Martin Babka}

\begin{document}

\maketitle

By $[m]$ we understand the set $\{1, \dots, m\}$.
Let $z \in [m]^n$. 
We define $z(x) := z_x$ and $p(z) = \sum_{i = 1}^{n} |z^{-1}(i)|^2$.

Let $h$ be an \emph{iteratively 4-wise independent function} mapping $[m]$ to $[n]$, i.e. a function satisfying that for each $x \in [m]$, $i_1, \dots, i_4 \in [n]$, $i_1 < \dots < i_4$, and $y_1, \dots, y_4 \in [n]$ it holds \[\prob{h^{i_1}(x)=y_1 \wedge \dots \wedge h^{i_4}(x)=y_4 \wedge \left|\{h^{i + 1}(x) \mid i \in [i_4]\}\right| = i_4}.\] 
Let $K = (k_1, \dots, k_s)$ be chosen randomly and 4-wise independently from $[n]^s$.
Let $f = h \circ z$.
Let $W_L(K) := k_1, f(k_1), f^2(k_1), \dots, f^{l_1}(k_1), k_2, f(k_2), \dots, f^{l_2}(k_2), k_3, \dots$ be a sequence generated by the following algorithm:
\begin{itemize}
    \item We start each run by the next value from $K$.
    \item We generate values using function $f$ applied to the previous value.
    \item We stop the run after adding a value $c$ which causes a collision with respect to $z$, i.e. there is a previous value $p$ in $W_L(K)$ such that $z(p) = z(c)$.
\end{itemize}

By \emph{$k$-independent random string} of values from $\{0, \dots, n - 1\}$ of length $L$  we understand a string $\beta \in [n]^L$ matching the two criteria: 
\begin{itemize}
    \item $\forall i \in \{1, \dots, L\}, y \in [n]$ it holds that $\prob{\beta_i = y} = n^{-1}$ and
    \item for each $K \subseteq L$, $|K| = k$ the values are $\beta(K)$ are independent.
\end{itemize}

\begin{lemma}
Fix $z$ with $p(z) \leq p$ and a positive integral value of $s$ such that $s \leq n^2/p$.
Put $L := \frac{1}{2}n\sqrt{\frac{s}{p}}$.
Let $\beta$ be a string generated by the above algorithm. 
Then $\prob{\beta\mbox{ contains }i^{*}\mbox{ and }j^{*}} \geq \Omega\left(\left(\frac{L}{n}\right)^2\right)$.
\end{lemma}
\begin{proof}
We need the following claims to prove the lemma.

\begin{claim}
$W_L(K)$ is a $4$-independent random string.
\label{claim-independence}
\end{claim}
\begin{proof}
We prove that for each $\{i_1, i_2, i_3, i_4\} \in \binom{[|\beta|]}{4}$ we have that $\beta_{i_1}, \beta_{i_2}, \beta_{i_3}, \beta_{i_4}$ are independent. Moreover for arbitrary $i \in |\beta|$ and $y \in [n]$ it holds that $\prob{\beta_{i} = y} = n^{-1}$.

The problem why we need to use iterative instead of a generic $4$-independence is that we do not choose the elements $x_1, \dots x_4$ arbitratily and fixed but their choice dpenends on $h$.
\end{proof}

\begin{claim}
There exists a iteratively $k$-independent system of functions.
\end{claim}
\begin{proof}
For iterative $k$-independency use $k$-degree polynomial over a field $\mathbb{Z}_p$.
When the elements generating the Vandermonde matrix are unique, independently on the way they are chosen, the relevant system of linear equations has just a unique solution.
\end{proof}

\begin{claim}
Tabulation is iteratively $3$-independent.
\end{claim}
\begin{proof}
$T[x_1^1] \oplus T[x_1^2] \oplus T[x_1^3] = y_1$
\end{proof}

\begin{claim}
Distribution of $W_L(K)$ is the same as the distribution of all $4$-independent random strings of length $L$ cut off after $s$-th repetition w.r.t. $z$.
\label{claim-cut-off}
\end{claim}
\begin{proof}
See the original proof. In the following we refer to the full length string as $\tilde \beta$ and $\beta$ is the prefix of $\tilde{\beta}$ cut off after the $s$-th repetition w.r.t. $z$, i.e. $W_L(K)$.
\end{proof}

The sketch is as follows.
\begin{align*}
    \prob{\beta\mbox{ contains }i^{*}\mbox{ and }j^{*}} 
        & \geq \prob{\beta\mbox{ contains }i^{*}\mbox{ and }j^{*} \wedge |\beta| = L} \\
        & = \prob{\tilde{\beta}\mbox{ contains }i^{*}\mbox{ and }j^{*} \wedge |\beta| = L} \\
        & = \prob{|\beta| = L \mid \tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*} \mid}\prob{\tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*} \mid}.
\end{align*}


\begin{claim}
\[ \prob{\tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*}} \geq \Omega\left(\left(\frac{L}{n}\right)^2\right). \]
\end{claim}
\begin{proof}
For $\{i, j\} \in \binom{[L]}{2}$ we define event $E_{i, j}$ as $\tilde \beta_i = i^* \wedge \tilde \beta_j = j^*$.
Notice that $n \leq p \leq n^2$ and $1 \leq s \leq n^2/p$.
Observe that we may bound $L = 1/2 \cdot n\sqrt{s/p} \in [1/2, n/2]$.
\begin{align*}
    \prob{\tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*}} 
        & \geq \sum_{\{i, j\} \in \binom{[L]}{2}} \prob{E_{i, j}} - \sum_{\substack{\{i, j\} \in \binom{[L]}{2} \\ \{k, l\} \in \binom{[L]}{2} \\ \{i, j\} \neq \{k, l\}}} \prob{E_{i, j} \wedge E_{k, l}} \\
        & \geq \frac{L(L-1)}{2} \cdot n^{-2} - L^3 \cdot n^{-3} - L^4 \cdot n^{-4} \\
        & \geq \Omega\left((L/n)^2\right).
\end{align*}
\end{proof}

\begin{claim}
\[ \prob{|\beta| = L \mid \tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*}} \geq \frac{1}{4}. \]
\end{claim}
\begin{proof}
We prove for $s = 1$. We define $E^{*}_{i, j} \equiv \tilde \beta_i = i^{*} \wedge \tilde \beta_j = j^{*}$ and $E^{*} \equiv \exists i \neq j \in \{1, \dots, L\} \colon E^{*}_{i, j}$.

Observe that
\begin{align*}
|\beta| = L \mid \tilde \beta\mbox{ contains }i^{*}\mbox{ and }j^{*} 
    & \equiv |\beta| = L \mid \exists i \neq j \in \{1, \dots, L\} \colon \tilde \beta_i = i^{*}\mbox{ and } \tilde \beta_j = j^{*} \\
    & \equiv |\beta| = L \mid E^{*} \\
    & \equiv \tilde \beta[L \setminus \{i, j\}] \mbox{ has no collisions} \wedge \tilde \beta[L \setminus \{i, j\}] \cap z^{-1}(i^{*}) = \emptyset \mid E^{*}.
\end{align*}

We prove that $\prob{\tilde \beta[L \setminus \{i, j\}] \mbox{ has a collision} \mid E^{*}} \leq 1/4.$
For $i \neq j \in \{1, \dots, L\}$ we define the event $C_{i, j}$ that $\tilde \beta_i$ and $\tilde \beta_j$ collide w.r.t. $z$ as $C_{i, j} \equiv z(\tilde \beta_i) = z(\tilde \beta_j)$.
From $4$-independence of $\tilde \beta$ we get $\prob{E_{k, l} \mid E^{*}} \leq 2p/n^2$.
Now by union bound $\prob{\tilde \beta[L \setminus \{i, j\}] \mbox{ has a collision} \mid E^{*}} \leq \binom{L}{2}\frac{2p}{n^2} \leq \frac{L^2p}{n^2} = \frac{s}{4}$.

It remains to show that $\prob{\beta[L \setminus \{i, j\}] \cap z^{-1}(i^{*}) \neq \emptyset \mid E^{*}} \leq 1/2.$ We define the event $C_k$ as $\tilde \beta_k \in z^{-1}(i^{*})$. From $4$-independence it holds that $\prob{C^{*}_k \mid E^{*}} \leq \frac{\sqrt{p}}{n}$. We may union bound the probability by $\frac{L\sqrt{p}}{n} \leq \frac{\sqrt{s}}{2}$.

For $s > 1$. Let $\operatorname{rep}$ be the number of repetitions in $\tilde \beta$ w.r.t. $z$ and $\operatorname{coll}$ be the number of collisions in $\tilde \beta$ w.r.t. $z$. 
From the previous we may bound $\expect{\operatorname{rep}} \leq \expect{\operatorname{coll}} \leq \sqrt{s}/2 + s/4 \leq \frac{3s}{4}.$
We use Markov inequality to bound $\prob{\operatorname{rep} = s} \leq \prob{\operatorname{rep} \geq s} \leq \frac{3}{4}.$ 
\end{proof}

\end{proof}
\end{document}
