\section{Model of Universal Hashing}
\label{section-model}
In this section we propose and analyze the model in case of separate chaining. 
The way we manage to achieve worst case lookup time is to keep chains shorter than the prescribed limit. 
First we introduce the concept of the limit function which bounds the length of the longest chain with a prescribed probability. 
It turns out that the time needed to keep chains short can be amortized to a constant in expectation.

\subsection{Limit function}
Each limit function has to depend on the size of the table, the load factor and the probability with which the bound holds. 
The following definition of a limit function takes into account the dependencies.

\begin{definition}[Limit function, trimming rate, suitable function]
\label{definition-limit-function}
The function $l\colon \mathbb{N} \times \mathbb{R}_0^+ \times (0, 1) \rightarrow \mathbb{N}$ is called a \emph{limit function} with \emph{trimming rate} $p$, $p \in (0, 1)$, if $\forall S \subseteq U\colon \Prob{\lpsl(S, f) > l(m, \alpha, p)} \leq p$.

We say that a function $f \in H$ is \emph{suitable} for $S$ and $l$ if $\,\lpsl(S, f) \le l(m, \alpha, p)$.
\end{definition}

\subsection{Algorithms}
The hash table may be adjusted by the following parameters.
\begin{itemize}
	\item {$m_0$}, initial size of the hash table;
	\item {$\alpha_l$, $\alpha_u$, $\alpha_l < \alpha_u$} -- we keep $\alpha \in [\alpha_l, \alpha_u]$, the lower bound may be violated when $m = m_0$;
	\item {$\alpha_m$, $\alpha_m \in (\alpha_l, \alpha_u)$} -- when rehashing because $\alpha \notin [\alpha_l, \alpha_u]$ we choose new $m$ so that $\alpha \sim \alpha_m$;
	\item \textbf{$\alpha'$, $\alpha_u < \alpha'$}, is the load factor for which the limit function is computed, thus $\lpsl(S, f) < l(m, \alpha', p)$.
\end{itemize}
The following three invariants briefly describe the model. 
\begin{itemize}
\item[(1)] \textbf{Universal class and limit function.} The used $c$-universal system $H$ has a limit function $l$ with a trimming rate $p$.
\item[(2)] \textbf{Load Factor Rule.} The load factor of the table is kept in the predefined interval $[\alpha_l, \alpha_u]$. For $m = m_0$ the lower bound may be violated.
\item[(3)] \textbf{Chain Length Limit Rule.} If there is a chain longer than $l(m, \alpha', p)$, then the table is rehashed using a new suitable function chosen uniformly at random from $H$.
\end{itemize}

For lower trimming rates the worst case guarantee tends to be weaker.
By different choices of the trimming rate we set up the trade-off between the worst case guarantee and the time spent per update.

\input{algorithms}

\subsection{Consequences of Trimming Long Chains}
We deal with the effects of Chain Length Limit Rule on the expected length of a chain.

\begin{definition}[$(l, p)$ - trimmed system]
\label{definition-trimmed-system}
Let $l$ be a limit function with a~trimming rate $p$.
The \emph{$(l, p)$-trimmed system} is the multiset of functions $H(p, l, S) = \{ f \in H \setdelim \lpsl(S, f) \leq l(m, \alpha', p) \}.$
\end{definition}

After each update we keep the function $f$ to be from the system $H(p, l, S)$.
On the other hand, it means that we do not use all the possible functions from $H$ and thus we have to reevaluate $\Expect{\psl}$.
We show that $(l, p)$-trimmed systems are still universal but with a higher constant of universality.
\begin{lemma}
\label{lemma-trimmed-system}
If $H$ is a $c$-universal system and $l$ is a limit function with a trimming rate $p$, then $|H(p, l, S)| \geq (1 - p)|H|$ and $H(p, l, S)$ is $c/(1 - p)$-universal.
\end{lemma}
\begin{proof}
From Definitions \ref{definition-trimmed-system} and \ref{definition-limit-function} it is clear that $\Prob{f \in H(p, l, S)} \geq 1 - p$. Hence $|H(p, l, S)| \geq (1 - p)|H|$.
For different $x, y \in U$ it holds that
\[
\begin{split}
& \Prob{f(x) = f(y) \mid f \in H(p, l, S)} 
	= \frac{\Prob{f(x) = f(y),\, f \in H(p, l, S)}}{\Prob{f \in H(p, l, S)}} \\
	& \qquad \leq \frac{\Prob{f(x) = f(y),\, f \in H}}{1 - p} = \frac{\Prob{f(x) = f(y) \mbox{ for } f \in H}}{1 - p}. \\
\end{split}
\]
The system $H(p, l, S)$ is thus $c/(1-p)$-universal.
\end{proof}

Lemma \ref{lemma-no-trials} gives an estimate on the expected number of trials needed to find a function $f \in H(p, l, S)$ if $f$ is chosen uniformly from $H$.
\begin{lemma}
\label{lemma-no-trials}
If $l$ is a limit function with a trimming rate $p$, then the expected number of trials needed to find a function from $H(p, l, S)$ is at most ${1}/{(1 - p)}$.
\end{lemma}
\begin{proof}
Because the subsequent choices are independent, the probability of having at least $k$ trials is at most $p^{k - 1}$. 
The expected number of trials is thus at most $\sum_{k = 1}^{\infty} p^{k - 1} = \sum_{k = 0}^{\infty} p^k = {1}/{(1 - p)}.$
\end{proof}

\subsection{Amortized Analysis}
We analyze the amortized complexity of the model with the potential method. 
Let $p_i$ be the potential of the hash table after performing the $i$\textsuperscript{th} operation and $t_i$ be the running time of the operation. 
We define the \emph{amortized complexity of the $i$\textsuperscript{th} operation} as $a_i = t_i + p_i - p_{i - 1}$. 
The expected complexity of a sequence of $k$ operations then equals $\Expect{T} = \sum_{i=1}^{k} \Expect{t_i} = \sum_{i = 1}^{k} \Expect{a_i - p_i + p_{i - 1}} = \sum_{i=0}^{k} \Expect {a_i} - \Expect{p_k} + \Expect{p_0}.$

\begin{theorem}
\label{theorem-amortised-expected-time}
If the hash table described in Algorithm \ref{algorithm-hash-table} is initially empty, then the expected amortized time complexity of each operation is constant and Find operation runs in $\bigo(1 + l(m, \alpha', p))$ time.
\end{theorem}
\begin{proof}
To prove the theorem assume that we are given a sequence of operations Insert, Delete and Find. 
We consider Insert and Delete successful or unsuccessful according to the comments in Algorithm \ref{algorithm-hash-table}.

First, we partition the analyzed sequence into two types of cycles. 
The first cycle type, $\alpha$-cycle, is used to amortize violations of Load Factor Rule. 
With the second type, $l$-cycles, which are partitioning of $\alpha$-cycles, we are able to distribute the time required to repair violations of Chain Length Limit Rule.

\begin{definition}[$\alpha$-cycle, $l$-cycle]
Cycles partition operations of the analyzed sequence.
Each \emph{$\alpha$-cycle} ends just after the operation causing violation of Load Factor Rule.
Each \emph{$l$-cycle} ends after the $(\alpha'-\alpha_u)m$-th successful insertion in the $l$-cycle or after an operation violating Load Factor Rule (both cycles end).
\end{definition}

First, we define the potential used in the proof.
Let $e = 1/(1 - p)$, $r$ be the number of tried hash functions because of a violation of Chain Length Limit Rule and $c_l$ be the number of started $l$-cycles.
Both $r$ and $c_l$ are counted from the initial state.
Let $i_\alpha$ be the number of successful insertions performed in an $\alpha$-cycle prior to the execution of an analyzed operation.
Similarly, $d_\alpha$ and $i_l$ denote the number of deletions and insertions in the $\alpha$-cycle and $l$-cycle before the operation.
We define $p_\alpha = {2ei_{\alpha}}/{(\alpha_u - \alpha_m)} + {2ed_{\alpha}}/{(\alpha_m - \alpha_l)}$ and $p_l = {ei_{l}}/{(\alpha' - \alpha_u)} + (ce - r) m$.
The overall potential $p_o = p_\alpha + p_l$.

At the end of each $\alpha$-cycle the size of the table has to change and Rehash operation is necessary.
We pay Rehash from the potential $p_\alpha$ accumulated in the $\alpha$-cycle.
When an $l$-cycle starts we pay in advance for the expected number of trials in it.
The potential required to prepay the cycle is accumulated during the previous $l$-cycle or in the initial potential.

Since Find and unsuccessful updates have no effect on the potential, we omit them from the analyzed sequence. 
The worst case complexity of Find follows directly from Chain Length Limit Rule because $\lpsl(S, f) \leq l(m, \alpha', p)$.
The expected running time of Find and unsuccessful updates is $\bigo\left(1 + \Expect{\psl}\right)$.
Since $(l, p)$-trimmed systems are $c/(1 - p)$-universal, the expected length of a chain is bounded from above by $c\alpha/(1 - p)$ and thus it is constant.

Now we analyze the sequence consisting of successful updates only. 
Observe that finishing an $l$-cycle, when the $\alpha$-cycle continues, does not change the potential.
Before starting a new cycle $i_l = (\alpha' - \alpha_u)m$.
Putting $i_l = 0$ and incrementing $c_l$ by one keeps the potential intact.
Each operation is split into the actual update and into a possible call of Rehash. 
These parts are analyzed separately.
\begin{itemize}
	\item \textbf{Update part.} 
The potential change caused by the update part is constant. 
For Insert we have $\Delta p_o = 2e/(\alpha_u - \alpha_m) + e/(\alpha' - \alpha_u)$ and for Delete $\Delta p_o = 2e/(\alpha_m - \alpha_l)$. 
Hence $\Delta p_o = \bigo(1)$.

	\item \textbf{$\alpha$-cycle ends.} 
At the end of an $\alpha$-cycle either $i_\alpha \geq (\alpha_u - \alpha_m)m$ or $d_\alpha \geq (\alpha_m - \alpha_l)m$. 
The potential change equals $\Delta p_\alpha + \Delta p_l \leq -2em + em \leq -em$.
After rescaling the potential we are able pay the time $\bigo(em)$ which by Lemma \ref{lemma-no-trials} is equal to the expected running time of Rehash.

	\item \textbf{Chain Length Limit Rule is violated.} 
Each trial of a function corresponds to a single iteration of the repeat loop in Rehash procedure of Algorithm \ref{algorithm-hash-table} and takes $\bigo(m)$ time. 
Because the value of $r$ is increased by the number of trials, the potential $p_l$ is decreased by $\Delta rm$. 
The time $\bigo\left(rm\right)$ taken by Rehash procedure is compensated by the loss of the potential.
\end{itemize}

Now we argue why the expected potential loss compensating the increase of $r$ cannot be high.
We show that $\Expect{p_o} \geq 0$ after any sequence of operations.
To do so we analyze the sequence of sets stored after the operations in an $l$-cycle.
If we omit deletes from the $l$-cycle, we get another sequence of sets created only by insertions.
Consider the set $S'$ at the end of the $l$-cycle in the insertion only sequence. 
Since there are at most $(\alpha' - \alpha_u)m$ insertions in the $l$-cycle and $\alpha' > \alpha_u$ we get that $|S'| \leq \alpha' m$.
Clearly, for each set $S$ represented in the dictionary during the $l$-cycle we have that $S \subseteq S'$. 
Therefore during the $l$-cycle we reject even smaller number of functions compared to the insertion only sequence.
From Lemma \ref{lemma-no-trials} it follows that we expect at most $e$ trials to find a suitable function for $S'$. 
Hence the expected number of trials during each $l$-cycle is at most $e$.
Since $c_l$ is incremented at the beginning of each $l$-cycle, we get that $\Expect{c_l e} \geq \Expect{r}$ and hence $\Expect{p_o} \geq 0$ after each operation.

The theorem now follows from the fact $\Expect{T} = \Expect{A} - \Expect{p_o} + \Expect{p_0} \leq \Expect{A} + \bigo(1)$ and because the amortized complexity of each operation is constant.
\end{proof}
