\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathabx}
\usepackage{geometry}
\usepackage{graphicx}
\geometry{
	b5paper,
	margin=1.5cm,
	top=1.75cm,
	bottom=1.75cm
}

\newcommand{\llinnm}[2]{\operatorname{L}_{\operatorname{lin}}({#1}, {#2})}
\newcommand{\llinn}[1]{\llinnm{#1}{#1}}
\newcommand{\hlinr}[1]{\operatorname{H}_{\operatorname{lin}}^{#1}}
\newcommand{\hlin}{\operatorname{H}_{\operatorname{lin}}}
\newcommand{\leap}[3]{\operatorname{\mathbf{leap}}({#1}, {#2}, {#3})}
\newcommand{\hfact}[2]{\operatorname{H}_{\operatorname{factor}}({#1}, {#2})}
\newcommand{\rot}[2]{\operatorname{H}_{\operatorname{rot}}^{{#1}, {#2}}}

\newcommand{\bin}[3]{\operatorname{\mathbf{bin}}({#1}, {#2}, {#3})}
\newcommand{\lbin}[2]{\operatorname{\mathbf{lbin}}({#1}, {#2})}
\newcommand{\vbin}[2]{\operatorname{\mathbf{bin}}({#1}, {#2})}
\newcommand{\vlbin}[1]{\operatorname{\mathbf{lbin}}({#1})}

\newcommand{\vecspace}[2]{\mathbb{Z}_{#1}^{#2}}
\newcommand{\binvecspace}[1]{\vecspace{2}{#1}}
\newcommand{\linearmaps}[2]{\mathcal{L}_{#1}^{#2}}
\newcommand{\surjectivelinearmaps}[2]{\mathcal{LS}_{#1}^{#2}}

\newcommand{\probs}[2]{\operatorname{\mathbf{Pr}}_{{#1}}\left[{#2}\right]}
\newcommand{\prob}[1]{\probs{}{#1}}
\newcommand{\expects}[2]{\operatorname{\mathbf{E}}_{{#1}}\left[{#2}\right]}
\newcommand{\expect}[1]{\expects{}{#1}}
\newcommand{\inu}{\in_U}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}


\title{Expected number of uniformly distributed balls in a most loaded bin using placement with simple linear functions}
\author{Martin Babka\thanks{Research supported by the Czech Science Foundation grant GA14-10799S.}}

\begin{document}

\maketitle

\begin{abstract}
We estimate the size of a most loaded bin when the balls, which are chosen from a transformed interval, are placed into the bins using a random linear function where the operations are taken in a finite field.
We show that in such a setting the expected load of the most loaded bins is constant.

This is an interesting fact because using fully random hash functions with the same class of input sets leads to an expectation of $\Theta\left(\frac{\log m}{\log \log m}\right)$ balls in most loaded bins where $m$ is the number of balls and bins.

Although the family of the functions is quite common both in theory and practice, the size of largest bins was not known even in this simple case.
\end{abstract}

\section{Introduction}

We estimate the size of a largest bin in a special case of the balls and bins model. The balls and bins model simply means placement of each ball into a bin in some random fashion. The process of the placement is of a various study -- choice of balls, randomness of placement, independence of the placement and especially the study how these properties affect the bin sizes.

The simplest model of the placement of the balls into bins is formed by using complete randomness and independence of the elements.
It is a well-known fact that if $m$ balls are thrown completely at random to $m$ bins, then the expected size of the largest bin is $\Theta\left(\frac{\log m}{\log \log m}\right)$.

There are various similar statements dealing with the estimates of bin sizes for various placement processes.
For example Carter and Wegman \cite{cw} showed that the expected size of a bin is constant when they assumed the placement by the functions which we will refer to as simple linear functions. These functions are two-wise independent and thus they trivially achieve $O(\sqrt{m})$ expected size of a largest bin. We tighten this result to $O(1)$ when the input set is a linearly transformed interval.

It is also possible to use functions of higher degree of independence and thus obtain better bounds. There are also lower bounds shown by Siegel \cite{siegel} for various trade-offs between the speed of such functions, size needed to represent them on one side and independence they achieve on the other side.

The need to improve the size of the largest bins leads to the two-choice paradigm. For the placement we use two functions and the ball is placed into the smaller bin out of the two chosen bins. In this model the size of the largest bin is $O(\log \log m)$ where $m$ is the number of balls and bins. This was first shown shown by Azar et al \cite{azar} and later improved by V\"{o}cking \cite{vocking}.

Nowadays more complicated family of functions are studied in \cite{celisetal}. The functions no longer rely on high degree of independence but are designed so that they achieve small largest bins with high probability.

\section{Notation and definitions}
\label{sec:notation}
We refer to the set $\{0, \dots, k - 1\}$ as to $[k]$. 
In the whole text we assume that $p$ is a fixed prime. 
The set of chosen balls is denoted by $S \subset [p]$.
The number of bins is the same as the number of balls and is denoted by $m$, i.e. $|S| = m$.

For each pair $(a, b) \in [p]^2$ we define the function $h'_{a, b}$ as $h'_{a, b}(x) = (ax + b) \bmod p$ and the function $h_{a, b}$ as $h_{a, b}(x) = h'_{a, b}(x) \bmod m$.

The multiset of simple linear functions mapping $[p]$ to the range $[m]$ is denoted by $\hlin$ and is defined as $\hlin = \{h_{a, b} \mid a, b \in [p] \}$.
For a function $h \in \hlin$ we define the size of $i$-th bin as $\bin{h}{S}{i} = |S \cap h^{-1}(i)|$ and the maximal size of the bin as $\lbin{h}{S} = \max_{i \in [m]} \bin{h}{S}{i}$.

In the following text we fix the probability space to be formed by a uniform choice of $h \in \hlin$.
The symbols $\vbin{S}{i}$ and $\vlbin{S}$ then refer to the random variables formed by the mentioned random uniform choice.

For an element $x$ we put the value $\leap{x}{a}{b} = \left\lfloor\frac{ax + b}{p}\right\rfloor$; that is how many \emph{leaps}, overflows over $p$, are caused by applying the function $h_{a, b}$ on the element $x$ in the field $\mathbb{Z}_p$. Notice that $(ax + b) \bmod  p = ax + b - \leap{x}{a}{b}p$.

Our model relies on the above random choice of the hash function $h_{a, b} \in \hlin$ and the fact that $S$ is a linear transformation of $[m]$ in $\mathbb{Z}_p$. In Theorem~\ref{thm:interval-constant} we show that the expected size of largest bin is $O(1)$.

\section{Collision probability for three elements}

We first study the probability of collision of three arbitrary elements.
By collision of the elements we understand the event when all of the elements are mapped to the same element in $[m]$ by the randomly chosen linear function.

We fix three different elements $x, y, z \in [p]$ and we count the number of pairs $(a, b) \in [p]^2$ such that $|h_{a, b}(\{x, y, z\})| = 1$.

We start by simplifying to the case when $x = 0, y = 1$ and the third element $z = d$ for a suitable $d \in [p]$ such that $d > 1$ depends on the choice of $x, y, z$.

\begin{lemma}[Transformation lemma]
\label{lemma:transformation}
Let $x, y, z \in [p]$ be arbitrary different elements. Moreover, assume that $i_x, i_y, i_z \in [m]$. Then there exist an element $d \in [p]$ such that
\[
\prob{h(x) = i_x, h(y) = i_y,  h(z) = i_z} = \prob{h(0) = i_x, h(1) = i_y, h(d) = i_z}.
\]
\end{lemma}
\begin{proof}
The idea of the proof is simple. We show that there is a one-to-one map between simple linear functions mapping $x, y, z$ to $i_x, i_y, i_z$ and simple linear functions transforming $0, 1, d$ to the same elements.

In the first part of the proof we observe that combining simple linear functions with a linear function in $\mathbb{Z}_p$ does not change the probability space.
There is a single linear function transforming $0, 1$ to $x, y$ in $\mathcal{Z}_p$ which we refer to as $h'_{\alpha,\beta}$.
Finally we choose $d$ so that $h'_{\alpha, \beta}(d) = z$ and the proof is finished.

We show that the elements $x, y, z$ can be transformed to the elements $0, 1, d$ so that the probability of the mappings from the statement of the lemma remains the same.

Choose $\alpha, \beta \in [p]$ so that $\alpha \neq 0$.
Observe that the mapping $(\gamma, \delta) \mapsto (\alpha \gamma, \beta \gamma + \delta)$ is a one-to-one map on $[p]^2$.
If there is another pair $(\epsilon, \phi)$ such that $(\alpha \epsilon, \beta \epsilon + \phi) = (\alpha \gamma, \beta \gamma + \delta)$, then $\gamma = \epsilon$ and $\delta = \phi$. Thus the mapping is injective.
Also for arbitrary $(r, s) \in [p]^2$ the element $(\alpha^{-1}r, s - \beta\alpha^{-1}r)$ is mapped to $(\alpha \alpha^{-1}r, \beta \alpha^{-1} r + s - \beta\alpha^{-1}r) = (r, s)$.

The compound function $h'_{a, b} \circ h'_{\alpha, \beta}$ is exactly equal to the function $h'_{\alpha a, \beta a + b}$; this also follows from the fact that the set of all linear functions in $\mathbb{Z}_p$ forms a group with the operation of compounding functions. 

Let $H' = \{h'_{a, b} \mid (a, b) \in [p]^2\}$.
From the previous we can conclude that the combination of a function $h' \in H'$ with a fixed function $h'_{\alpha, \beta}$ is a one-to-one map in the space of functions $H'$.
Also observe that the composition of a function $h_{a, b} \in \hlin$ with $h'_{\alpha, \beta}$ can not change the probability (count of the functions) of mapping arbitrary three elements to a their prescribed images.

There is also a single function $(\alpha, \beta) \in [p] ^ 2$, i.e. a single function $h'_{\alpha, \beta}$, transforming the elements $0$ and $1$ to $x$ and $y$ in the field $[p]$ without taking modulo $m$. It is the function $\beta = x$ and $\alpha = y - x$.
To prove the lemma we choose $d \in [p]$ such that $h'_{\alpha, \beta}(d) = z$, i.e. $d = \alpha ^ {-1}(z - \beta)$.
\end{proof}

Lemma \ref{lemma:transformation} shows that the probability properties, e.g. collision, mapping to the prescribed elements, for the elements $x, y, z$ are the same as for the elements $\{0, 1, d\}$ where $d$ comes from the previous lemma.

Next we estimate the collision probability for the elements $0, 1, d$.

\begin{lemma}[Probability of collision of three elements]
\label{lemma:probability-3-elements}
Let $d \in [p]$ be arbitrary element.
\[
\prob{|h(\{0, 1, d\})| = 1 } \leq \frac{\lceil \lceil\frac{p}{d}\rceil / m \rceil\left\lceil\frac{d}{m}\right\rceil}{p}.
\]
\end{lemma}
\begin{proof}
We count the number of functions $h \in \hlin$ such that $h(\{0, 1, d\}) = \{y\}$ for some $y \in [m]$.
For each $x \in [p]$ it holds that $\leap{x}{a}{b} \in [x]$ and $h(x) = (ax + b - \leap{x}{a}{b}p) \bmod m$.

Whenever the elements $0, 1$ and $d$ are mapped to the same element $y$ it must hold that $h(0) = h(1)$ and $h(0) = h(d)$. Hence
\begin{align*}
	b \bmod p \bmod m & = (a + b) \bmod p \bmod m \\
	b \bmod p \bmod m & = (da + b) \bmod p \bmod m. \\
\end{align*}
From which we obtain the following sequence of equivalent equations
\begin{align*}
	m & \mid a + b - \leap{1}{a}{b}p - b \\
	m & \mid da + b - \leap{d}{a}{b}p - b, \\
\end{align*}
\begin{align*}
	m & \mid a - \leap{1}{a}{b}p \\
	m & \mid da - \leap{d}{a}{b}p, \\
\end{align*}
\begin{align*}
	m & \mid da - d\leap{1}{a}{b}p \\
	m & \mid (d\leap{1}{a}{b} - \leap{d}{a}{b})p. \\
\end{align*}
Since $p$ is a prime the subtraction of the two last equations yields $m \mid d\leap{1}{a}{b} - \leap{d}{a}{b}$.
We estimate the collision probabilities from the first equation in the second step and from the last observation:
\begin{align}
	m & \mid a - \leap{1}{a}{b}p \label{3-prob-1-statement} \\
	m & \mid d\leap{1}{a}{b} - \leap{d}{a}{b}. \label{3-prob-2-statement}
\end{align}

The statement (\ref{3-prob-2-statement}) roughly means that out of $d$ possible values for $\leap{d}{a}{b}$ only the $1 / m$ fraction may generate the collision of the three elements. Notice that for a fixed $l \in [d]$ it holds that $\{a \in [p] \mid \leap{d}{a}{b} = l\}$ is a subinterval of $[p]$.
From (\ref{3-prob-1-statement}) we can observe that only the $1 / m$ fraction from the possible values of $a$ lying in the appropriate intervals allowed by valid values of $\leap{d}{a}{b}$ are causing collisions.

For the rest of the proof fix the value of $b$. 
First, we show that the values of $a$ such that $\leap{d}{a}{b} = l \in [d]$ form disjoint intervals in $[p]$ each of size at most $\lceil p/d \rceil$.
Then we count the number of values $a$ in an interval causing collisions -- using (\ref{3-prob-1-statement}).
And finally we count the number of the valid intervals, i.e. the intervals satisfying equation (\ref{3-prob-2-statement}).

Let $\leap{d}{a}{b} = l$, i.e. $l \leq \frac{da + b}{p} < l + 1$. Immediately we get that $a \in \left[\frac{pl - b}{d}, \frac{p(l + 1) - b}{d}\right) \cap \mathbb{Z}$. The total number of values of $a$, i.e. integers, in each valid interval is at most $\lceil p / d \rceil$. The ceiling must be applied. For example assume an interval of length of 1.5 starting at point 0.8 -- it contains two integer points 1 and 2. This happens whenever $\frac{pl - b}{d}$ is an integer.

Now fix the value $l \in [d]$ such that $\leap{d}{a}{b} = l$.
In order to estimate the number of values of $a$ causing the collisions we split into two cases according to the value of $\leap{1}{a}{b}$.

\subparagraph{The first case, $\leap{1}{a}{b} = 0$.} 
From the two previous statements we conclude that
\begin{align*}
	m & \mid a \\
	m & \mid l. \\
\end{align*}

\subparagraph{The second case, $\leap{1}{a}{b} = 1$.}
As in the first case it must hold that
\begin{align*}
	m & \mid a - p \\
	m & \mid d - l. \\
\end{align*}

In both cases, there are at most $\lceil d/m \rceil$ values of $l$ satisfying the  condition (\ref{3-prob-2-statement}).
Also for each satisfying value of $l$ there are at most $\lceil \lceil\frac{p}{d}\rceil / m \rceil$ values of $a$ causing the collision.

\end{proof}

The probability of collision of the three elements can be bounded as
\[
\frac{\left(1 + \frac{1 + \frac{p}{d}}{m}\right)\left(1 + \frac{d}{m}\right)}{p} =
\begin{cases}
	\frac{O(1)}{m^2} + \frac{1}{dm} + O\left(p^{-1}\right) & \mbox{if } d \leq p/m \\
	\frac{O(1)}{m^2} + \frac{d}{pm} + O\left(p^{-1}\right) & \mbox{otherwise, i.e. } \frac{p}{m} \leq d < p.
\end{cases}
\]

The worst possible case is for $d = 2$ and the probability is roughly $1/2m$. 
When $d \geq p/m$, the formula is a great overestimate as shown in Figure~1.
% When $d \geq p/m$, the formula is a great overestimate as shown in Figure~\ref{fig:probability-3}.

\begin{figure}[h]
	\label{fig:probability-3}
	\centering
	% \includegraphics[width=8cm]{coll-3-21787-512-scaled.png}
	\caption{The function of probability of collision of the elements $0, 1, d$ with respect to $d$. Notice that the probability is decreasing in the part when $d \leq p / m$ and is almost symmetric. In this figure $m = 512$ and $p = 21787$.}
\end{figure}

\begin{corollary}
\label{co:d-elements}
Let $d \leq p / m$. Then $\prob{|h([d])| = 1} \leq \frac{1}{(d - 1) m} + O(1)/m^2 + O(p^{-1})$.
\end{corollary}
\begin{proof}
When all the elements from $[d]$ collide, then the elements $\{0, 1, d - 1\}$ must collide as well. The probability of the collision of $\{0, 1, d - 1\}$ is hence a valid upper bound on the probability of the collision of the whole interval. The statement is then a direct application of Lemma~\ref{lemma:probability-3-elements}.
\end{proof}

For completeness we just show a simple fact that our probability estimate is tight when we have a stronger assumption, namely we assume $p > 3m^2$.

\begin{lemma}
\label{lm:0-d-prob-lower-bound}
If $d \leq m$ and $p > 3m^2$, then $\prob{|h(\{0, 1, \ldots, d - 1\})| = 1} = \Omega\left(\frac{1}{dm}\right).$
\end{lemma}
\begin{proof}
For a fixed $b$, if $a < (p - b)/d$ and $m \mid a$, then the elements $\{0, 1, \ldots, d - 1\}$ must collide.
For each $b$ there are at least $\lfloor (p - b)/dm \rfloor$ such values of $a$.

We conclude that the number of pairs $(a, b)$ making the elements collide is at least
\[
\sum_{b \in [p]} \left(\frac{p - b}{dm} - 1\right) = \frac{(p + 1)p}{2dm} - p \geq \frac{p ^ 2 - 2pdm}{2dm} \geq \frac{p^2}{6dm}.
\]

Thus the resulting probability is at least $\frac{1}{6dm}$.
\end{proof}

\section{The structure of elements in a single bin}

First realize that for each $i \in [m]$ it holds that $h^{-1}(i) = \{a^{-1} (i + j m - b) \mid j \in [p / m]\}$ where the operations are taken in $\mathbb{Z}_p$.
Thus for $\alpha = a^{-1}m$ and $\beta = i-a^{-1}b$ we see that $h^{-1}(i)$ is the image of a linear transformation of the interval $[p / m]$. Precisely $h^{-1}(i) = \alpha [p/m] + \beta$ where the operations are taken in $\mathbb{Z}_p$.

Notice that for a fixed $0 < m < p$, there is a one-to-one map among the pairs $(a, b)$ and $(\alpha, \beta)$.

From the almost two-wise independence of $\hlin$ we can derive the following property. {\color{red} Is it really from the two-wise independence? How does this property relates to the two-wise independence?}

\begin{lemma}
Assume that $g, f \in [p] \setminus \{0\}$ and $I = \left[\frac{p}{m}\right]$. Then \[\left\lfloor \frac{f^{-1}g}{m} \right\rfloor \left\lfloor \frac{1}{f^{-1}g} \left\lfloor\frac{p}{m}\right\rfloor \right\rfloor \leq |gI \cap fI| \leq \left\lfloor \frac{f^{-1}g}{m} \right\rfloor \left\lceil \frac{p}{f^{-1}gm} \right\rceil.\]
\end{lemma}
\begin{proof}
We begin the proof by simplifying the statement using the fact that $|gI \cap fI| = |f^{-1}gI \cap I|$. Hence without loss of generality we may assume that $f = 1$.

From now on we are estimating $|gI \cap I|$.
We count the number of $x \in I$ such that $gx \in I$.
First, trivially, for each $0 \leq x < \frac{p}{gm}$ we know that $gx \in I$.
Observe that no $x \in I \setminus \left\{ 0, \dots, \left\lfloor {p}/{(gm)} \right\rfloor \right\}$ such that $\leap{x}{g}{0} = 1$ satisfies the condition $gx \in I$.

Realize that the similar observations hold for each possible leap and there are $g$ leaps. More precisely -- each leap adds at least $\left\lfloor \frac{\lfloor p/m \rfloor}{m} \right\rfloor$ and at most $\left\lceil \frac{p}{gm} \right\rceil$ elements to the final intersection.

Since there are $\lfloor\frac{gp}{mp}\rfloor$\footnote{This may be less by 1 since the $\lfloor p/m \rfloor$ element is the last and the expression thus can be by one smaller.} leaps we get that $\left(\lfloor\frac{g}{m}\rfloor - 1\right) \left\lfloor \frac{p}{gm} \right\rfloor \leq |gI \cap I| \leq \lfloor \frac{g}{m}\rfloor\left\lceil \frac{p}{gm} \right\rceil$.
\end{proof}

In order to continue we have to perform a more detailed analysis of the leaps and possible overflows so that we get tighter bounds.
The previous lemma yields good results only for $1 < g \leq p/m$ which is just a $1/m$ fraction of the possible values of $g$.

\begin{lemma}
Assume that $g, f \in [p] \setminus \{0\}$ and $I = \left[\frac{p}{m}\right]$. Then $|gI \cap fI| \leq O(p/m^2)$.
\end{lemma}
\begin{proof}
First, assume that $f = 1$. And let us denote $\lfloor p/m \rfloor$ as $\phi$.
Now realize that there are two types of leaps long and short. The long leaps add $\lceil \phi / g \rceil$ to the result and the short ones add only $\lfloor \phi / g \rfloor$.

So we know that $|gI \cap I| = \#\operatorname{leaps} \cdot \lfloor \phi / g \rfloor + \#\operatorname{long-leaps} \leq (g/m) \left\lceil p/gm  \right\rceil.$ The number of leaps from the previous proof is at most $g/m$. If $g \leq p/m$, then we get that $|I \cap gI| \leq O(p/m^2)$ and we are finished. From now on assume that $g > p/m$. Also notice that the contribution of short leaps to the intersection is zero.

The number of long leaps can be estimated similarly as $|g'[g/m] \cap I|$ for $g' = (-p) \bmod g$ where the operations are taken in $\mathbb{Z}_g$.
Similarly $|g'[g/m] \cap I| \leq \lfloor g'/m \rfloor \lfloor p/mg' \rfloor + \#\operatorname{long-leaps}$. If $g' \leq p/m$, then we are finished otherwise we have to go down one level in the similar way.
\end{proof}

The following is a straightforward application of the previous lemma.
\begin{corollary}
Let $a, a' \in [p] \setminus {0}$ and let $i \in [m]$. Then it holds that $|h_{a, 0}^{-1}(i) \cap h_{a', 0}^{-1}(i)| = 1/m^2$.
\end{corollary}

\section{The expected size of most loaded bins}

First we study the role of the parameter $b$ in the hash function $h_{a, b}$.
% TODO: Mention that for universality it is not so much required but makes a good constant and independence.

The following lemma states that the effect of $b$ on $\vlbin{S}$ is not asymptotic since it more or less only shifts the largest bin.
\begin{lemma}
\label{lm:b-zero}
Assume that  $a, b \in [p]$ and $S \subseteq [p]$. Then \[ \frac{1}{2} \lbin{h_{a, b}}{S} \leq \lbin{h_{a, 0}}{S} \leq 2\lbin{h_{a, b}}{S} . \]
\end{lemma}
\begin{proof}
Let $L \subseteq S$ be elements of bin $y$, i.e. $h_{a, b}(L) = y$.
For each $x \in L$ we have that 
\begin{align*}
h_{a, 0}(x) 
	& = ax \bmod p \bmod m \\ 
	& = (ax + b - b) \bmod p \bmod m \\ 
	& = \begin{cases}
((ax + b) \bmod p - b \bmod p)\bmod m & \mbox{ if } (ax + b) \bmod p \geq b \\
(p + (ax + b) \bmod p - b \bmod p) \bmod m & \mbox{ otherwise.} \\
\end{cases}
\end{align*}

Notice that the two possible new bins are either $(y - b) \bmod m$ or $(p + y - b) \bmod m$.
The lemma now follows from the following two observation.
First each original bin is either shifted and keeps its size or is split into two possibly uneven shifted bins -- hence $\frac{1}{2} \lbin{h_{a, b}}{S} \leq \lbin{h_{a, 0}}{S}$.
And notice that each new bin can only contain elements from at most two different original bins and thus $\lbin{h_{a, 0}}{S} \leq 2\lbin{h_{a, b}}{S}$.
\end{proof}

The change of the sign of $a$ has almost no effect on $\vlbin{S}$.
\begin{lemma}
\label{lemma:sign-a}
Assume that  $a \in [p]$ and $S \subseteq [p]$ such that $0 \not\in S$. Then \[ \lbin{h_{a, 0}}{S} = \lbin{h_{p - a, 0}}{S} . \]
\end{lemma}
\begin{proof}
Similarly as in the proof of the previous lemma. Let $L \subseteq S$ be elements of bin $y$, i.e. $h_{a, 0}(L) = y$.
Let $x \in L$, then $h_{p - a, 0}(x) = (p - a)x \bmod p \bmod m = (p - ((ax) \bmod p))\bmod m = (p - y) \bmod m$.
When $x \neq 0$, then $(p - a)x \bmod p = p - ((ax) \bmod p)$.
The bin $y$ is thus moved to the bin $(p - y) \bmod m$ and the lemma holds.
\end{proof}

Obviously allowing zero makes only an one element difference.
\begin{corollary}
Let $S \subseteq [p]$, then
\[
\lbin{h_{a, 0}}{S} -1 \leq \lbin{h_{p - a, 0}}{S} \leq \lbin{h_{a, 0}}{S} + 1.
\]
\end{corollary}

\section{The equation $ax \bmod p \bmod m = y$}

Finding the structure of the solutions of the equation $ax \bmod p \bmod m = y$ for $x \in [m]$ enables us to find a structure of elements of a chain. 
Precisely we show that the chains are unions of at most two different arithmetic progressions. 
We also show that the solutions of the above equation for $y = 0$ form a finite arithmetic progression starting at $0$. 

\begin{lemma}
\label{lemma-equation}
Let $a \in [p]$ and $y \in [m]$. Then the set of all solutions of the equation $ax \bmod p \bmod m = y$ for $x \in [m]$ is a union of at most two arithmetic progressions having the same difference.
\end{lemma}
\begin{proof}
First realize that the statement can be rewritten as $[m] \cap a^{-1}y + a^{-1}m [p/m]$ is a union of at most two arithmetic progressions.

In the following claim the notation $x \cdot_G y$ means that the operation is taken in $\mathbb{Z}_{G}$, i.e. $x \cdot_G y = xy \bmod G$. 
\begin{claim}
\label{claim:arithmetic-progression}
Let $G$ be a positive integer and $g, h \in [G]$. We prove that $[m] \cap h +_G g \cdot_{G} [G/m]$ is a union of at most two arithmetic progressions having the same difference.
\end{claim}
\begin{proof}
We proceed by induction on $G$.

Assume that $G < m$, then $[G/m] = \{0\}$ and the statement holds trivially.

Let $G \geq m$ be arbitrary and assume that $g \leq m$, then we obtain the wanted statement with the following two arithmetic progressions with the difference exactly $g$.
If $h < m$, then the first progression starts at $h$.
The second progression, if it exists, is the one exactly after a possible leap, i.e. assume that $j$ is the minimal integer such that $h + gj > G$. Then the second progression starts at $h'$ where $h' = (h + gj) \bmod G$.

Assume that $g > m$.
Now observe that each leap over $G$ may intersect with $[m]$ only in the first elements of the leaps because the difference between the elements is $g > m$.
We show that the elements of the leaps possibly intersecting with $[m]$ are of the form $h' +_{G} j\cdot_{G}(-G)$ where $h' \in [g]$ and $j \in [g/m]$.
Let $j$ be a non-negative integer.
The first element in the $j + 1$-th leap equals $h + gk_j - jG$ where $k_j$ is the minimal integer such that $h + gk_j > jG$.
Since $h + gk_j - jG < g$ we get that $h + gk_j - jG = (h + gk_j - jG) \bmod g = h +_{G} (j \cdot_{G}(-G))$.
Now if $h < m$, then the first leap, i.e. $j = 0$ intersects with $[m]$. 
In this case the set of all possible intersections is of the form $h + (j(-G)) \bmod g$ for $j \in [g/m]$.
When $h > m$, then the first leap may not intersect with $[m]$ and the set of all possible intersections now looks like $h \bmod g +_G (j(-G)) \bmod g$ for $j \in [1 + g/m ] - \{0\}$. The set of the elements can be rewritten as $(h - G) \bmod g +_G j\cdot_G(-G)$ for $j \in [g/m]$.
In both cases we get the wanted statement from the induction hypothesis.
\end{proof}

The lemma follows from a simple application of the previous claim by using $G := p$ and $g := a^{-1}m \bmod p$.
\end{proof}

From the proof of Lemma~\ref{lemma-equation} one can observe a special version of the above lemma.
\begin{corollary}
Let $a \in [p]$. The solutions of the equation $ax \bmod p \bmod m = 0$ for $x \in [m]$ form an arithmetic progressions starting at $0$.
\end{corollary}
\begin{proof}
Put $h = 0$ and observe that in this case the second progression does not occur.
\end{proof}

\section{Main theorem}

For the choice of $S = [m]$ we show that the expected size of a most loaded bin is within $O(1)$. 
This can be compactly formulated as follows.
\begin{theorem}
\label{thm:interval-constant}
Assume that $p \geq m^2$, then
\[
\expect{\vlbin{[m]}} = O(1).
\]
\end{theorem}
\begin{proof}
By Lemma~\ref{lm:b-zero} we may assume that the chosen function has $b = 0$ without asymptotically increasing the expected size of the largest bin. 
Moreover we may assume that $a \neq 0$. 
Notice that this assumption adds at most $m/p$ to the computed expected value which is $O(1)$.

By Lemma~\ref{lemma-equation} each bin is formed by at most two arithmetic progressions. Both arithmetic progressions have the same difference $d$.
If there is a bin of size $l$, then there is an arithmetic progression chosen from $[m]$ of size at least $\lceil \vlbin{[m]}/2 \rceil \geq l/2$ collapsing into a single bin.
It is the longer arithmetic progression from the two progressions forming the bin.

We want to estimate the probability of having such a progression.
We start by showing that whenever there is a progression colliding into a single bin, then the progression starting at $0$ having the same difference and length also collides to a single bin with probability $1/2$.
The proof of the statement follows in Claim~\ref{claim-normalize-progression}. From the claim and the definition of the conditional probability we conclude that 
\begin{align*}
\prob{\vlbin{[m]} \geq l} & \leq \prob{\exists d, s \in [m] \colon s+d\lfloor l/2 \rfloor < m \wedge |h(s + d[l/2])| = 1} \\
	& \leq 2 \prob{\exists d \colon h(d([l/2])) = \{0\}}.
\end{align*}

\begin{claim}
\label{claim-normalize-progression}
For every $d, l \in [m]$ such that $l \geq 3$, $dl \leq m$ it holds 
\[\probs{a\in[p]}{h_{a,0}(d[l]) = \{0\} \mid \exists s \in [m - dl]\colon |h_{a,0}(s + d[l])| = 1} = \frac{1}{2}.\]
\end{claim}
\begin{proof}
If $ad \bmod p < p/2$, then the arithmetic progression starting at $0$ of length $l$ and difference $d$ collides into bin $0$. 
Consider elements $s$, $s + d$ and $s + 2d$.
There are at least two of them colliding without having a leap in $\mathbb{Z}_p$ and thus $m \mid ad$.
Since the whole progression $s + d[l]$ collides into a single bin under $h_{a,0}$ we conclude that there are no leaps in the sequence $(as) \bmod p + ((ad) \bmod p)[l]$, i.e. $(as) \bmod p + ((ad) \bmod p)[l] < p$.
Otherwise the leap would cause that $s + d[l]$ would be split into two bins since $m \mid ad$ but certainly $m \nmid (ad - p)$.
Since exactly one half of the values of $a$ satisfy $ad < p/2$ the claim holds.

Let us note that whenever $ad \bmod p > p/2$, then $(p - a)d \bmod p = p - (ad \bmod p) < p/2$ and thus from Lemma~\ref{lemma:sign-a} it follows that the progression $d[l-1]$ collides under $h_{p - a, 0}$ into a single bin.
\end{proof}

Since for a fixed difference $d$ and length $l \geq 3$ there are at most $\frac{m}{l}$ possible arithmetic progressions starting at $0$ from which we may choose from. By Corollary~\ref{co:d-elements} we upper bound the probability of the collapse of an arithmetic progression using the union bound as 
\[
\frac{m}{l} \left(\frac{1}{lm} + 1/m^2 + O(p^{-1})\right) \leq O(l^{-2}).
\]

For $l \geq 5$ we get $\prob{\vlbin{[m]} \geq l} = O(2(l / 2)^{-2}) = O(l^{-2})$ and hence
\[
\expect{\vlbin{[m]}} \leq 4 + \sum_{l = 5}^m O\left(l^{-2}\right) = O(1).
\]

An alternative finish of the proof could use the fact that the longest bin contains $0$ with conditional probability $1/2$ and thus $\expect{\vlbin{[m]}} \leq 3 + O(\expect{\vbin{[m]}{0}})$.
\end{proof}

We can conclude the main result, i.e. each set transformable to $[m]$ in $\mathbb{Z}_p$ has constant sized largest bins.
\begin{corollary}
Let $a, b \in [p]$. 
Then $\expect{\vlbin{a[m] + b}} = O(1)$.
\end{corollary}
\begin{proof}
Direct corollary of Theorem~\ref{thm:interval-constant} since by Lemma~\ref{lemma:transformation} the probabilistic properties of $[m]$ do not change under the transformation $x \mapsto (ax + b) \bmod p$.
\end{proof}


\section{A Special Case for $S$ Being a Vector Subspace}

Let us note that when $S$ is a subspace of the universe, then all the non-empty bins are of the same size.
First notice that the bins have a simple structure -- all of them are formed by elements which are affine subspaces of the universe.
This means that bins have the same size and in addition the bin of vector $0$ in $\binvecspace{2}$ always exists and is a largest bin of expected constant size.

\begin{theorem}
Let $b, u \in \mathbb{N}$ and $v_1, \dots, v_b \in \mathbb{Z}_2^u$ be linearly independent. Then \[ \expects{h \in_U \linearmaps{u}{b}}{\lbin{h}{\operatorname{Span}(v_1, \dots, v_b)}} = O(1) .\]
\end{theorem}
\begin{proof}
For convenience put $S = \operatorname{Span}(v_1, \dots, v_b)$. 
We show that each non-empty bin created by a transformation $h$ is formed by balls from an affine subspace of $S$ and has the size of the kernel of $h$.
From this it follows that $\expect{\lbin{h}{S}} = \expect{\bin{h}{S}{0}} = O(1)$.

Without loss of generality assume that $v_1, \dots, v_k$ are the vectors forming the kernel of $h$, i.e. $h(v_i) = 0$ where $i \in \{1, \dots, k\}$.
If $h(v) = y$ for some $v \in S$, then $h^{-1}(y) \cap S = v + \operatorname{Span}(v_1, \dots, v_k)$.
Hence for each $y \in \mathbb{Z}_2^b$ it holds hat $|h^{-1}(y) \cap S| = 0 \vee |h^{-1}(y) \cap S| = 2^k$.
Thus the sizes of all the non-empty bins are the same and are equal to $\bin{h}{S}{0}$.
\end{proof}



We present a different proof of this property coming from the following ideas.
Notice that the structure of the bins can give an upper bound of having $l$ colliding elements.
The fact that we can find a bin which is always present avoids using the union bound.

\begin{theorem}
\label{theorem-bound-general}
If $A \subseteq \binvecspace{b}$, $\alpha_0 = 1 - |A|/2^b$, then \[\probs{f_1, \dots, f_b \in_U \binvecspace{b}}{1 - |A \cup (A + \operatorname{Span}(f_1, \dots, f_b)|/2^b \geq \mu} \leq \alpha_0^{b - \log \log \mu^{-1} + \log \log \alpha_0^{-1}}.\]
\end{theorem}
\begin{proof}
In~\cite{alonetal}.
\end{proof}

There is a chain of length at least $2^l$ iff $\operatorname{dim}(\operatorname{Ker}(T)) \geq l$, i.e. $\operatorname{rank}(T) < b - l$.
Let $e_1, \dots, e_b$ be the canonical basis of $\binvecspace{b}$. For each $e_i$ mapping  $T$ choses its image $f_i \in_U \binvecspace{b}$.
Mapping $T$ has rank less than $b - l$ iff $|\operatorname{Span}(f_1, \dots, f_b)| < 2^{b - l}$, i.e. $1 - |\operatorname{Span}(f_1, \dots, f_b)|/2^b > 1 - 2^{-l}$.
In our setting it holds $T(S) = \operatorname{Span}(f_1, \dots, f_b)$.
Hence $\lbin{T}{S} \geq 2^l$ iff $1 - |\operatorname{Span}(f_1, \dots, f_b)|/2^b > 1 - 2^{-l}$.

If we directly apply Theorem~\ref{theorem-bound-general} for $A = \{\vec{0}\}$ and the vectors $f_1, \dots, f_b$ chosen by $T$ we get the following estimate:
\[
\probs{}{\lbin{T}{S} \geq 2^l} \leq (1 - 2^{-b})^{b - \log (-\log (1 - 2^{-l})) + \log (-\log (1 - 2^{-b}))} \approx (1 - 2^{-b})^{b + l - b} \leq (1-2^{-b})^{l}.
\]
This is not sufficient to get $O(1)$ bound since the bound provided by Theorem~\ref{theorem-bound-general} for $\alpha_0$ close to $1$ is not tight.
Consider $A = \{\vec{0}\}$, i.e. $\alpha_0 = 1 - 2^{-b}$ and we add a single random vector $\vec{v}$ to $A$, i.e. $\alpha_1 = 1 - |A \cup (A + \vec{v})|/2^b$, then $\probs{v\in_U\binvecspace{b}}{\alpha_1 \geq 1 - 2^{-b}} = 2^{-b}$ since this is equivalent to $v = \vec{0}$.
From Theorem~\ref{theorem-bound-general} we get only
\[
\probs{v\in_U\binvecspace{b}}{\alpha_1 \geq 1 - 2^{-b}} \leq \alpha_0^{1 - \log \log \alpha_0^{-1} + \log \log \alpha_0^{-1}} = 1 - 2^{-b}.
\]
Compare $2^{-b}$ to the bound $1-2^{-b}$ obtained from the direct application of Theorem~\ref{theorem-bound-general}.

To get a sufficient result we use factorization similar to the one used in the proof of Theorem~7a in~\cite{alonetal}. It ensures that $\alpha_0$ is large enough.
First we bound the probability of having many collisions under a universal function $T$ following from using CSB and Markov inequalities.
This is a generalization of the well-known property of universal functions saying that $\probs{T \in_U \linearmaps{u}{b}}{\mbox{number of collisions created by }T \geq \frac{k}{2^b} \binom{|S|}{2}} \leq \frac{1}{k}$.
\begin{lemma}
\label{lemma-collisions-general}
\[
\probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq \frac{|S|}{k}} \leq \frac{|S| - 1}{(k - 1)2^b} \leq \frac{|S|}{k2^b}.
\]
\end{lemma}
\begin{proof}
Use CSB to bound the number of collisions from below and then use Markov inequality to obtain the probability bound.
\end{proof}

Now we switch back to bounding the probability of having a long chain.
We factor through a vector space $F$ of dimension $b$, i.e. the dimension of both source and target space.
The factorization is as usual, $T = T_0 \circ T_1$ where $T_1$ is surjective.

\begin{align*}
& \probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq 2^{b - l}} \\
& \quad \leq \probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq 2^{b - l} \wedge |T_0(S)| \leq 2^{b - \sqrt{l}}} + \probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq 2^{b - l} \wedge |T_0(S)| > 2^{b - \sqrt{l}}} \\
& \quad \leq \probs{T \in_U \linearmaps{u}{b}}{|T_0(S)| \leq 2^{b - \sqrt{l}}} + \probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq 2^{b - l} \mid |T_0(S)| > 2^{b - \sqrt{l}}}.
\end{align*}
Now by Lemma~\ref{lemma-collisions-general} we get
$
\probs{T \in_U \linearmaps{u}{b}}{|T_0(S)| \leq 2^{b - \sqrt{l}}} \leq 2^{-\sqrt{l}}.
$
Let us fix $T_0$ and denote $S_1 = T_0(S)$. From Theorem~\ref{theorem-bound-general} it follows that 
\[
\probs{T \in_U \linearmaps{u}{b}}{|T(S)| \leq 2^{b - l} \mid |T_0(S)| > 2^{b - \sqrt{l}}} = 
\probs{T_1 \in_U \surjectivelinearmaps{f}{b}}{|T_1(S_1)| \leq 2^{b - l} \mid |S_1| > 2^{b - \sqrt{l}}}.
\]
Directly use the following fact used in the proof of Theorem~7b in \cite{alonetal}.
Let $A \subseteq \binvecspace{u}$, $\alpha = 1 - |A|/2^u$
\[
\probs{T \in_U \surjectivelinearmaps{u}{b}}{1 - |T(A)|/2^b \geq 1 - 2^{-l}} \leq \alpha^{u - b - \log \log \left(1 - 2^{-l}\right)^{-1} + \log \log \alpha^{-1}}.
\]
Since $-2^{-l} \geq \log(1 - 2^{-l})$ we get
$
\probs{T \in_U \surjectivelinearmaps{u}{b}}{1 - |T(S)|/2^b \geq 1 - 2^{-l}} \leq \alpha^{u - b + l + \log \log \alpha^{-1}}.
$
In our case we have $u := b$, $b := b$, $T := T_1$, $A := S_1$ and $\alpha \leq 1-2^{-\sqrt{l}}$.
Moreover whenever $l \geq 2$, we have that $-2^{-l/2 + 1} \leq \log (1 - 2^{-l/2})$ and $1-2^{-\sqrt{l}} \leq e^{-\log(2)\sqrt{l}} \leq 2^{-\sqrt{l}}$.
Finally
\begin{align*}
& \probs{T_1 \in_U \surjectivelinearmaps{f}{b}}{|T_1(S_1)| \leq 2^{b - l} \mid |S_1| > 2^{b - 2\log l}} \\
& \quad = \probs{T_1 \in_U \surjectivelinearmaps{f}{b}}{1 - |T_1(S_1)|/2^b \geq 1 - 2^{-l} \mid |S_1| > 2^{b - 2\log l}} \\
& \quad \leq \left(1 - 2^{-2\log l}\right)^{l + 1 - l/2} \leq e^{-2^{-\sqrt{l}}(l/2 + 1)} \leq e^{-\sqrt{l}/2}.
\end{align*}

\section{Natural set for the multiply-shift system}

\begin{definition}[Mutliply-shift system]
Let $k, b \in \mathbb{N}$, $k \geq b$ and $a \in [2^k]$, $2 \nmid a$.
Let the function $h_a$, $h_a \colon [2^k] \to [2^b]$, map $x$ to $h_a(x) =(ax \bmod 2^k) \div 2^{k - b}$.
The system $\mathcal{MS}_{k}^{b} = \{h_a \mid a \in [2^k], 2 \nmid a\}$ is called \emph{multiply-shift system}.
\end{definition}

Let $m = 2^b$.
The best possible case is when $S = [m] + 2^{k} - m$. Then there is no function which creates a collision on such a set.
The elements of $S$ are numbers with the $k-b$ least significant bits equal to zero.

Let $x, y \in S$, $x \neq y$. Observe that for any $a \in [2^k]$, $2 \nmid a$, we have $ax \bmod 2^k \neq ay \bmod 2^k$ and the $k - b$ least significant bits of both values are zeros.
Hence $h_a(x) \neq h_a(y)$.

We can prove $\expects{T}{\lbin{T}{S}} = O(1)$ for $S = [m]$.
Let us note that for an odd $a$ the sets $[m]$ and $a[m]$ have the same behavior with respect to $\mathcal{MS}_{k}^{b}$ since multiplication by an odd number just permutes the functions.
From this it follows that for any $a \in [2^k]$, $2 \nmid a$ and $S = a[m]$ we get the same expectation as for $S = [m]$. 
\begin{lemma}
When $k \geq 2b$ and $S = [2^b]$, then $\expects{T}{\lbin{T}{S}} = O(1)$.
\end{lemma}
\begin{proof}
Let $y \in [2^b]$, then $h_a^{-1}(y) = (a^{-1} (y + [2^{k - b}])) \bmod 2^k$ where the inverse of $a$ is taken in $[2^k]$.
\begin{claim}
Let $\operatorname{GCD}(g, 2^k) = 1$, then $g(y + [2^{k - b}]) \bmod 2^{k} \cap [2^b]$ is a union of at most two arithmetic progressions.
\end{claim}
\begin{proof}
If $g < 2^b$, then the claim holds since $g2^{k - b} < 2^k$. The shift by $yg$ can split the arithmetic progression with the difference $g$ intersecting with $[2^{b}]$ into at most two progressions.

If $g > 2^b$, then from the assumption that $k \geq 2b$  we get that the elements in the intersection are the first elements from the leaps over $2^k$. We use an inductive argument on the first elements of leaps intersecting the input set, i.e. $((-2^k) \bmod a) [ma/2^k] \cap [2^b]$.
\end{proof}

\begin{itemize}
 \item The longest chain is always formed with $0$ as its smallest element.
 \item Probability of collision of an arithmetic progression of length $l$ into a single element
\end{itemize}
\end{proof}

\section{Natural set for linear functions modulo prime}

\section{Factorisation of the multiply-shift-system}

\begin{theorem}
Let $w, f, b \in \mathbb{N}$ such that $w > f \geq b$.
Each $h_\alpha \in \mathcal{MS}_{u}^{b}$ can be decomposed into $i_\beta^{p} \in \mathcal{MS}_{u}$ and $j_\gamma^{f} \in \mathcal{MS}_{f}^{b}$ such that $\alpha = \beta (\gamma 2 ^ {w - f} + 1)$.
\end{theorem}
\begin{proof}
Let $x_f = (\beta x \bmod 2^w) \div 2^{w - b}$ and $t_f = \beta x \bmod 2^f$.

\begin{align*}
j_\gamma(i_\beta(x)) & = \left(x_f + \gamma t_f\right) \bmod 2^b \\
	& = \left(x_f 2^{w-b} + \gamma t_f 2^{w-f}\right) \bmod 2^w \div 2^{w-b} \\
	& = \left(\beta x \bmod 2^w + \gamma \right(\beta x \bmod 2^f\left) 2^{w-f}\right) \bmod 2^w \div 2^{w-b} \\
	& = \left(\beta x \bmod 2^w + \gamma 2^{w-f} \left(\beta x \bmod 2^f\right)\right) \bmod 2^w \div 2^{w-b} \\
	& = \left(\beta x \bmod 2^w + \left(\gamma 2^{w-f}\beta x\right) \bmod 2^w\right) \bmod 2^w \div 2^{w-b} \\
	& = \beta \left(\gamma 2^{w - f} + 1\right) x \bmod 2^w \div 2^{w - b} \\
	& = \alpha x \bmod 2^w \div 2^{w - b} \\
	& = h_\alpha(x).
\end{align*}
\end{proof}

\bibliographystyle{siam}
\bibliography{slf-int}

\end{document}


