\section{Introduction}
Dictionary is a data structure which allows storing and querying data associated with each stored key. 
Dictionaries are often implemented with \emph{hash tables}. 
This implementation is utilized especially in the case when the set of the possible keys is not linearly ordered or when the performance of the dictionary is crucial to its application.
With hash tables we can easily and efficiently perform operations \emph{Find}, \emph{Insert} and \emph{Delete}.
In this paper we are interested in dynamic dictionaries, we allow update operations, and provide a guaranteed lookup time.
Running times of the operations strongly depend on the properties of the chosen hash function and usually they are considered to be constant in expectation. 
Hash tables are therefore considered to be one of the most efficient solutions to dictionary problem.

\subsection{Known results and methods}
Hashing is an old method and has overcome a great development. 
The first methods of \emph{plain hashing}, formerly separate chaining and linear probing or more recently Hopscotch hashing \cite{DBLP:conf/wdag/HerlihyST08}, rely on the randomness of the input data. 
They were analyzed using assumptions of full randomness, a complete list may be found in \cite{DBLP:books/sp/Mehlhorn84} which are not always met.

In some situations we can not rely on the randomness of input and switch to a randomization provided by a uniform selection of a hash function from a universal family. 
This method is known as \emph{universal hashing} and was pioneered by Carter and Wegman in \cite{DBLP:journals/jcss/CarterW79}. 
Find operation runs in expected constant time but in general no non-trivial worst case bound is known.

\emph{Perfect hashing} \cite{Fredman:1984:SST:828.1884} is an extension of universal hashing which addresses the problem of worst case running time for Find operation in case of static dictionaries. 
In order to add update operations various dynamizations of perfect hashing \cite{DBLP:journals/siamcomp/DietzfelbingerKMHRT94} and a real time hash table \cite{DBLP:conf/icalp/DietzfelbingerH90} were proposed. 
These methods together with cuckoo hashing \cite{DBLP:conf/esa/PaghR01} guarantee a constant worst case lookup time and the other operations run in expected amortized constant time.
Currently the most outstanding method is Backyard Cuckoo Hashing \cite{DBLP:conf/focs/ArbitmanNS10} which address the problem of worst case time for updates and memory consumption of cuckoo hashing.
It achieves constant running times of the operations with high probability.

\subsection{Our results}
Our aim is to address the gap between perfect hashing and common universal hashing.
First, we analyze a simple and natural modification of universal hashing with separate chains.
We bound their lengths by a convenient probabilistic limit function and rehash the table whenever there exists a chain violating this condition.
Our analysis shows that this approach leads to constant expected amortized times with a worst case guarantee for lookup.

The main advantage of the model is its simplicity and no need for a perfect hash function when compared to dynamic perfect hashing.
To compare with cuckoo hashing, we utilize a different approach which unfortunately does not achieve a constant worst case running time.
On the other hand we can tune the space consumption of the hash table, and the speed loss is compensated by use of simpler universal classes.
By design it addresses the dynamic resizing which causes certain problems in case of Backyard Cuckoo Hashing.

The proposed technique is generic. It may be used with double hashing and linear probing, too. 
When compared to two-level perfect hashing with linear memory we provide a more detailed analysis. 
We need each chain to be short not only the sum of squares of their lengths.
Furthermore using two-level hashing is possible and significantly improves the worst case guarantee.

\subsection{Notation}
The set $U$ denotes the universe, the set of possible keys. $V$ denotes the addresses of the hash table. We refer to $S \subset U$ as to the set of stored keys. The size of the hash table is denoted by $m = |V|$ and the number of stored elements is $n = |S|$, usually $n \ll |U|$. The load factor of the table is denoted by $\alpha = \frac{n}{m}$. It is kept in a predefined interval so that the space is not wasted and its maximal value is usually less than one.

The mapping $f\colon U \rightarrow V$ denotes the current hash function. We discuss probabilistic properties of hash functions and their families in more detail later.

We often work with the following two random variables defined for a fixed stored set~$S$. The length of the chain at address $y \in V$ is denoted by $\psl(y, S)$. The length of the longest chain, $\lpsl(S)$, is defined as $\lpsl = \max_{y \in V} \psl(y, S).$ We omit the parameter $S$ when we talk about bounds that hold for any $S \subseteq U$.

From now we assume the uniform choice of a hash function $f$ from a universal system.

\begin{definition}[$c$-universal system \cite{DBLP:journals/jcss/CarterW79}]
\label{definition-c-universal-system}
Let $H$ be a multiset of hash functions from $U$ to $V$. We say that $H$ is a \emph{$c$-universal system}, for $c > 0$, if for arbitrary different $x, y \in U$: $\left|\lbrace f \in H \setdelim f(x) = f(y) \rbrace\right| \leq {c|H|}/{m}$.\footnote{The set on the left side of the expression is also considered to be a multiset.}
\end{definition}

An equivalent restatement of the definition in probability terms requires that $\Prob{f(x) = f(y)} \leq c/m$. There are also various extensions of $c$-universality which include strong \emph{$k$-universality} \cite{DBLP:conf/focs/WegmanC79}, which is also called \emph{$k$-wise independence} \cite{DBLP:conf/focs/WegmanC79}, \emph{strongly $\omega$-universal} \cite{DBLP:conf/focs/WegmanC79} systems and \emph{uniform} \cite{DBLP:journals/siamcomp/PaghP08} systems.
\begin{definition}
Let $k > 0$ be an integer. System of functions $H$ is
\begin{itemize}
	\item \emph{strongly $k$-universal} with constant $c > 0$ if for any sequence of $k$ pairwise different elements $x_1, \dots, x_k \in U$ and arbitrary $y_1, \dots, y_k \in V$ \[\Prob{f(x_1) = y_1, \dots, f(x_k) = y_k} \leq \frac{c}{m^k}\mbox{,}\]
	\item \emph{strongly $k$-universal} if it is strongly $k$-universal with $c = 1$,
	\item \emph{strongly $\omega$-universal} if it is strongly $k$-universal for each $k \in \{1, \dots, |U|\}$,
	\item \emph{(almost) uniform} if it is (almost) strongly $n$-universal.
\end{itemize}
\end{definition}

Notice that strongly $k$-universal systems behave fully random for up to $k$ different elements and provide only so called \emph{limited randomness} for more than $k$ elements. On the other hand functions chosen from strongly $\omega$-universal systems behave like truly random functions. Because we need truly random estimates up to $n$ elements, then the concept of uniform systems is as powerful as $\omega$-universality.

Organization of the paper is as follows. In Sect.~\ref{section-model} we state the requirements on the used universal class, describe and analyze the proposed model. Section~\ref{section-limit} deals with various well-known universal systems and connects them with the model. In Sect.~\ref{section-conclusion} we point out further extensions and alternatives which bring practical improvement.
